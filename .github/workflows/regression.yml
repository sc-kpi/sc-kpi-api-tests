name: Regression Tests

on:
  workflow_dispatch:
    inputs:
      suite:
        description: "Test suite to run"
        required: true
        default: smoke
        type: choice
        options:
          - smoke
          - regression
          - all
      api_branch:
        description: "sc-kpi-api branch to checkout & build"
        required: false
        default: develop
        type: string
      environment:
        description: "Config profile"
        required: true
        default: ci
        type: choice
        options:
          - ci
          - staging
      base_url:
        description: "Override base URL (skips Docker startup if set)"
        required: false
        default: ""
        type: string
      auth_enabled:
        description: "Enable authentication"
        required: false
        default: true
        type: boolean
      thread_count:
        description: "Parallel thread count"
        required: true
        default: "5"
        type: choice
        options:
          - "1"
          - "3"
          - "5"
          - "10"
      rerun_failed:
        description: "Rerun only failed tests from a previous run"
        required: false
        default: false
        type: boolean
      previous_run_id:
        description: "Run ID to rerun failed tests from (required if rerun_failed=true)"
        required: false
        default: ""
        type: string

  workflow_call:
    inputs:
      suite:
        type: string
        required: true
        default: smoke
      api_branch:
        type: string
        required: false
        default: develop
      environment:
        type: string
        required: true
        default: ci
      base_url:
        type: string
        required: false
        default: ""
      auth_enabled:
        type: boolean
        required: false
        default: true
      thread_count:
        type: string
        required: true
        default: "5"
      rerun_failed:
        type: boolean
        required: false
        default: false
      previous_run_id:
        type: string
        required: false
        default: ""

concurrency:
  group: regression-${{ github.run_id }}

permissions:
  contents: write
  pages: write
  id-token: write
  actions: read

jobs:
  api-tests:
    name: API Regression (${{ inputs.suite }})
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout test repo
        uses: actions/checkout@v4

      - name: Checkout sc-kpi-api
        if: inputs.base_url == ''
        uses: actions/checkout@v4
        with:
          repository: sc-kpi/sc-kpi-api
          ref: ${{ inputs.api_branch }}
          path: sc-kpi-api

      - name: Generate JWT secret
        if: inputs.base_url == ''
        run: echo "JWT_SECRET=$(openssl rand -base64 32)" >> "$GITHUB_ENV"

      - name: Start services
        if: inputs.base_url == ''
        working-directory: sc-kpi-api
        run: docker compose up -d --build --wait --wait-timeout 180
        env:
          SPRING_PROFILES_ACTIVE: dev
          JWT_SECRET: ${{ env.JWT_SECRET }}

      - name: Wait for API health
        if: inputs.base_url == ''
        run: |
          timeout=120
          while [ $timeout -gt 0 ]; do
            if curl -sf http://localhost:8080/actuator/health > /dev/null 2>&1; then
              echo "API is healthy"
              exit 0
            fi
            sleep 2
            timeout=$((timeout - 2))
          done
          echo "API failed to become healthy within 120s"
          docker compose -f sc-kpi-api/docker-compose.yml logs api --tail 50
          exit 1

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "25"

      - name: Setup Gradle
        uses: gradle/actions/setup-gradle@v4

      - name: Download previous testng-output
        if: inputs.rerun_failed == true && inputs.previous_run_id != ''
        uses: actions/download-artifact@v4
        with:
          name: testng-output
          path: build/testng-output/
          run-id: ${{ inputs.previous_run_id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Run tests
        id: run-tests
        if: inputs.rerun_failed == false
        run: |
          ARGS="./gradlew ${{ inputs.suite }}"
          ARGS="$ARGS -Denv=${{ inputs.environment }}"
          ARGS="$ARGS -DthreadCount=${{ inputs.thread_count }}"
          ARGS="$ARGS -Dauth.enabled=${{ inputs.auth_enabled }}"
          ARGS="$ARGS -DignoreFailures=true"
          ARGS="$ARGS --no-daemon"
          if [[ -n "${{ inputs.base_url }}" ]]; then
            ARGS="$ARGS -DbaseUrl=${{ inputs.base_url }}"
          fi
          echo "Running: $ARGS"
          eval $ARGS

      - name: Auto-retry failed tests
        id: auto-retry
        if: inputs.rerun_failed == false && always() && steps.run-tests.outcome == 'failure'
        run: |
          FAILED_XML="build/testng-output/testng-failed.xml"
          if [[ -f "$FAILED_XML" ]]; then
            echo "Found testng-failed.xml, rerunning failed tests..."
            cp "$FAILED_XML" src/test/resources/testng/suites/testng-failed.xml
            ./gradlew test -Dsuite=testng-failed.xml \
              -Denv=${{ inputs.environment }} \
              -DthreadCount=${{ inputs.thread_count }} \
              -Dauth.enabled=${{ inputs.auth_enabled }} \
              -DignoreFailures=true --no-daemon
          else
            echo "No testng-failed.xml found, skipping auto-retry"
          fi

      - name: Rerun failed tests (manual)
        id: manual-rerun
        if: inputs.rerun_failed == true
        run: |
          FAILED_XML="build/testng-output/testng-failed.xml"
          if [[ ! -f "$FAILED_XML" ]]; then
            echo "::error::testng-failed.xml not found. Make sure the previous run ID is correct and had failures."
            exit 1
          fi
          echo "Rerunning failed tests from run ${{ inputs.previous_run_id }}..."
          cp "$FAILED_XML" src/test/resources/testng/suites/testng-failed.xml
          ./gradlew test -Dsuite=testng-failed.xml \
            -Denv=${{ inputs.environment }} \
            -DthreadCount=${{ inputs.thread_count }} \
            -Dauth.enabled=${{ inputs.auth_enabled }} \
            -DignoreFailures=true --no-daemon

      - name: Upload TestNG output
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: testng-output
          path: build/testng-output/
          retention-days: 14
          if-no-files-found: ignore

      - name: Upload Allure results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: allure-results
          path: build/allure-results/
          retention-days: 14

      - name: Upload TestNG reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: testng-reports
          path: build/reports/tests/
          retention-days: 14

      - name: Checkout gh-pages for Allure history
        if: always()
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: gh-pages
        continue-on-error: true

      - name: Generate Allure report
        if: always()
        uses: simple-elf/allure-report-action@v1.13
        with:
          allure_results: build/allure-results
          allure_report: allure-report
          gh_pages: gh-pages
          allure_history: allure-history
          keep_reports: 50

      - name: Fix Allure report permissions
        if: always()
        run: sudo rm -rf allure-history/.git

      - name: Deploy Allure report to GitHub Pages
        if: always()
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_branch: gh-pages
          publish_dir: allure-history

      - name: Telegram notification
        if: always()
        run: |
          ALLURE_URL="https://sc-kpi.github.io/sc-kpi-api-tests/${{ github.run_number }}/"
          GITHUB_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          SUMMARY_FILE="allure-report/widgets/summary.json"
          if [[ -f "$SUMMARY_FILE" ]]; then
            PASSED=$(jq -r '.statistic.passed // 0' "$SUMMARY_FILE")
            FAILED=$(jq -r '.statistic.failed // 0' "$SUMMARY_FILE")
            BROKEN=$(jq -r '.statistic.broken // 0' "$SUMMARY_FILE")
            SKIPPED=$(jq -r '.statistic.skipped // 0' "$SUMMARY_FILE")
            UNKNOWN=$(jq -r '.statistic.unknown // 0' "$SUMMARY_FILE")
            TOTAL=$(jq -r '.statistic.total // 0' "$SUMMARY_FILE")
            DURATION_MS=$(jq -r '.time.duration // 0 | floor' "$SUMMARY_FILE")
            TOTAL_SECS=$((DURATION_MS / 1000))
            HOURS=$((TOTAL_SECS / 3600))
            MINUTES=$(( (TOTAL_SECS % 3600) / 60 ))
            SECONDS=$((TOTAL_SECS % 60))
          else
            PASSED=0; FAILED=0; SKIPPED=0; BROKEN=0; UNKNOWN=0; DURATION=0
            for f in build/test-results/*/TEST-*.xml; do
              [[ -f "$f" ]] || continue
              PASSED=$((PASSED + $(grep -oP 'tests="\K[0-9]+' "$f" | head -1)))
              FAILED=$((FAILED + $(grep -oP 'failures="\K[0-9]+' "$f" | head -1)))
              SKIPPED=$((SKIPPED + $(grep -oP 'skipped="\K[0-9]+' "$f" | head -1)))
              FILE_TIME=$(grep -oP 'time="\K[0-9.]+' "$f" | head -1)
              DURATION=$(echo "$DURATION + $FILE_TIME" | bc)
            done
            PASSED=$((PASSED - FAILED - SKIPPED))
            TOTAL=$((PASSED + FAILED + SKIPPED))
            TOTAL_SECS=$(echo "$DURATION / 1" | bc)
            HOURS=$((TOTAL_SECS / 3600))
            MINUTES=$(( (TOTAL_SECS % 3600) / 60 ))
            SECONDS=$((TOTAL_SECS % 60))
          fi

          SUITE_NAME="${{ inputs.suite }}"
          SUITE_DISPLAY="${SUITE_NAME^}"

          if [[ $TOTAL -eq 0 ]]; then
            STATUS="BROKEN"
            STATUS_ICON="üü°"
          elif [[ $((FAILED + BROKEN)) -gt 0 ]]; then
            STATUS="FAILED"
            STATUS_ICON="üî¥"
          else
            STATUS="PASSED"
            STATUS_ICON="üü¢"
          fi

          if [[ $TOTAL -gt 0 ]]; then
            PASS_RATE=$((PASSED * 100 / TOTAL))
            FILLED=$((PASS_RATE / 5))
          else
            PASS_RATE=0
            FILLED=0
          fi
          EMPTY=$((20 - FILLED))
          BAR=$(printf '‚ñà%.0s' $(seq 1 $FILLED 2>/dev/null))$(printf '‚ñë%.0s' $(seq 1 $EMPTY 2>/dev/null))

          WF_START=$(gh run view ${{ github.run_id }} --json createdAt -q '.createdAt')
          START_EPOCH=$(date -d "$WF_START" +%s)
          NOW_EPOCH=$(date +%s)
          WF_ELAPSED=$((NOW_EPOCH - START_EPOCH))
          WF_HOURS=$((WF_ELAPSED / 3600))
          WF_MINUTES=$(( (WF_ELAPSED % 3600) / 60 ))
          WF_SECONDS=$((WF_ELAPSED % 60))

          if [[ $HOURS -gt 0 ]]; then
            DURATION_FMT="${HOURS}h ${MINUTES}m ${SECONDS}s"
          else
            DURATION_FMT="${MINUTES}m ${SECONDS}s"
          fi

          if [[ $WF_HOURS -gt 0 ]]; then
            WF_TIME_FMT="${WF_HOURS}h ${WF_MINUTES}m ${WF_SECONDS}s"
          else
            WF_TIME_FMT="${WF_MINUTES}m ${WF_SECONDS}s"
          fi

          SETUP="‚Äî suite: ${{ inputs.suite }}"
          SETUP+=$'\n'"‚Äî api_branch: ${{ inputs.api_branch }}"
          SETUP+=$'\n'"‚Äî environment: ${{ inputs.environment }}"
          SETUP+=$'\n'"‚Äî auth_enabled: ${{ inputs.auth_enabled }}"
          SETUP+=$'\n'"‚Äî thread_count: ${{ inputs.thread_count }}"
          SETUP+=$'\n'"‚Äî rerun_failed: ${{ inputs.rerun_failed }}"
          if [[ -n "${{ inputs.base_url }}" ]]; then
            SETUP+=$'\n'"‚Äî base_url: ${{ inputs.base_url }}"
          fi
          if [[ -n "${{ inputs.previous_run_id }}" ]]; then
            SETUP+=$'\n'"‚Äî previous_run_id: ${{ inputs.previous_run_id }}"
          fi

          MESSAGE="‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª
          <b>SC KPI API ${SUITE_DISPLAY} ‚Äî ${STATUS} ${STATUS_ICON}</b>

          <code>${BAR}</code>  ${PASS_RATE}% (${PASSED}/${TOTAL})

          <b>Suite:</b> ${SUITE_NAME}
          <b>Environment:</b> ${{ inputs.environment }}
          <b>Duration:</b> ${DURATION_FMT}
          <b>Workflow time:</b> ${WF_TIME_FMT}
          ‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª
          ‚úÖ   Passed: <b>${PASSED}</b>
          ‚õîÔ∏è   Failed: <b>${FAILED}</b>
          ‚è≠Ô∏è   Skipped: <b>${SKIPPED}</b>
          ‚ö†Ô∏è   Broken: <b>${BROKEN}</b>
          ‚ÅâÔ∏è   Unknown: <b>${UNKNOWN}</b>

          ‚Äî <b>Total tests executed</b>: ${TOTAL}
          ‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª
          <b>Workflow setup:</b>
          ${SETUP}
          ‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª
          üìä <a href=\"${ALLURE_URL}\">Allure Report</a>
          üîó <a href=\"${GITHUB_RUN_URL}\">GitHub Run</a>
          ‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª"

          curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
            -d chat_id="${TELEGRAM_CHAT_ID}" \
            -d message_thread_id="${TELEGRAM_TOPIC_ID}" \
            -d parse_mode="HTML" \
            -d disable_web_page_preview="true" \
            --data-urlencode "text=${MESSAGE}" || echo "::warning::Telegram notification failed"
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          TELEGRAM_TOPIC_ID: ${{ secrets.TELEGRAM_TOPIC_ID }}
          GH_TOKEN: ${{ github.token }}

      - name: Add Job Summary
        if: always()
        run: |
          REPORT_URL="https://sc-kpi.github.io/sc-kpi-api-tests/${{ github.run_number }}/"
          cat >> "$GITHUB_STEP_SUMMARY" <<EOF
          ## Regression Test Results

          | Parameter | Value |
          |-----------|-------|
          | **Suite** | \`${{ inputs.suite }}\` |
          | **Environment** | \`${{ inputs.environment }}\` |
          | **API Branch** | \`${{ inputs.api_branch }}\` |
          | **Base URL** | \`${{ inputs.base_url || 'http://localhost:8080 (Docker)' }}\` |
          | **Auth Enabled** | \`${{ inputs.auth_enabled }}\` |
          | **Thread Count** | \`${{ inputs.thread_count }}\` |
          | **Allure Report** | ${REPORT_URL} |
          EOF

      - name: Dump API logs on failure
        if: failure() && inputs.base_url == ''
        working-directory: sc-kpi-api
        run: docker compose logs api --tail 200

      - name: Cleanup
        if: always() && inputs.base_url == ''
        working-directory: sc-kpi-api
        run: docker compose down -v
